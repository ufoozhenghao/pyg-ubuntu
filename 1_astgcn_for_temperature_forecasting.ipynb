{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:01:30.393215Z",
     "start_time": "2024-11-05T02:01:30.384731Z"
    }
   },
   "source": [
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda:0')\n",
    "print(\"CUDA:\", USE_CUDA, DEVICE)\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "sw = SummaryWriter(logdir='.', flush_secs=5)\n",
    "\n",
    "import math\n",
    "from typing import Optional, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.typing import OptTensor\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.transforms import LaplacianLambdaMax\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, get_laplacian\n",
    "from torch_geometric.utils import to_dense_adj"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "728facee-37c1-4bc2-b6d0-33c2827015a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:06:10.851894Z",
     "start_time": "2024-11-05T02:06:10.846178Z"
    }
   },
   "source": [
    "'''\n",
    "加载图信号数据，并将其转换为 PyTorch 的 DataLoader\n",
    "流程：\n",
    "1.转换数据类型：将 NumPy 数组转换为 PyTorch 张量，并确保它们的数据类型为浮点数。\n",
    "2.移动到设备：将张量移动到指定的设备（如 GPU）。\n",
    "3.创建数据集：使用 TensorDataset 将输入张量和目标张量配对，创建一个数据集对象。\n",
    "4.创建数据加载器：使用 DataLoader 将数据集分成小批量，并设置是否打乱数据。\n",
    "'''\n",
    "def load_graphdata_channel1(graph_signal_matrix_filename, num_of_hours, batch_size,\n",
    "                            shuffle=True, DEVICE = torch.device('cuda:0')):\n",
    "    \"\"\"\n",
    "    :param graph_signal_matrix_filename: str\n",
    "    :param num_of_hours: int\n",
    "    :param num_of_days: int\n",
    "    :param num_of_weeks: int\n",
    "    :param DEVICE:\n",
    "    :param batch_size: int\n",
    "    shuffle：是否在训练数据加载器中打乱数据。\n",
    "\n",
    "    :return:\n",
    "    three DataLoaders, each dataloader contains:\n",
    "    test_x_tensor: (B, N_nodes, in_feature, T_input)\n",
    "    test_decoder_input_tensor: (B, N_nodes, T_output)\n",
    "    test_target_tensor: (B, N_nodes, T_output)\n",
    "    \"\"\"\n",
    "\n",
    "    # file = os.path.basename(graph_signal_matrix_filename).split('.')[0]\n",
    "    new_working_directory = '/media/nevo/DOCUMENT/OneDrive/100 大体积混凝土温控研究/双屿门大桥/code/ASTGCN-PYG/pytorch_geometric_temporal/notebooks/data/heat'\n",
    "    os.chdir(new_working_directory)\n",
    "    current_directory = os.getcwd()\n",
    "    print(\"当前工作目录:\", current_directory)\n",
    "    print('load file:', graph_signal_matrix_filename)\n",
    "    file_data = np.load(graph_signal_matrix_filename)\n",
    "\n",
    "    train_x = file_data['train_x']  # (10181, 307, 3, 12)\n",
    "    train_x = train_x[:, :, 0:1, :]\n",
    "    train_target = file_data['train_target']  # (10181, 307, 12)\n",
    "\n",
    "    val_x = file_data['val_x']\n",
    "    val_x = val_x[:, :, 0:1, :]\n",
    "    val_target = file_data['val_target']\n",
    "\n",
    "    test_x = file_data['test_x']\n",
    "    test_x = test_x[:, :, 0:1, :]\n",
    "    test_target = file_data['test_target']\n",
    "\n",
    "    mean = file_data['mean'][:, :, 0:1, :]  # (1, 1, 3, 1)\n",
    "    std = file_data['std'][:, :, 0:1, :]  # (1, 1, 3, 1)\n",
    "\n",
    "\n",
    "    # ------- train_loader -------\n",
    "    train_x_tensor = torch.from_numpy(train_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
    "    train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    '''\n",
    "    torch.from_numpy 将 NumPy 数组转换为 PyTorch 张量。\n",
    "    .type(torch.FloatTensor) 将张量的数据类型转换为 FloatTensor，即 32 位浮点数\n",
    "    .to(DEVICE) 将张量移动到指定的设备（如 GPU 或 CPU）\n",
    "    torch.utils.data.TensorDataset 创建一个数据集对象，该对象将输入张量和目标张量配对,返回一个TensorDataset对象\n",
    "    TensorDataset 是PyTorch中的数据集类，用于将多个张量组合成一个数据集。每个样本由输入张量和目标张量组成。\n",
    "    torch.utils.data.DataLoader 创建一个数据加载器，用于批量加载数据\n",
    "    DataLoader 是PyTorch中的一个类，用于将数据集分成小批量，并在训练过程中方便地迭代数据。\n",
    "    '''\n",
    "\n",
    "\n",
    "    # ------- val_loader -------\n",
    "    val_x_tensor = torch.from_numpy(val_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
    "    val_target_tensor = torch.from_numpy(val_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_x_tensor, val_target_tensor)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # ------- test_loader -------\n",
    "    test_x_tensor = torch.from_numpy(test_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
    "    test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # print 打印数据尺寸\n",
    "    print('train:', train_x_tensor.size(), train_target_tensor.size())\n",
    "    print('val:', val_x_tensor.size(), val_target_tensor.size())\n",
    "    print('test:', test_x_tensor.size(), test_target_tensor.size())\n",
    "\n",
    "    return train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, mean, std"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "cd1af1e2-dcd0-44d8-8520-0ad95aa118ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:06:11.831379Z",
     "start_time": "2024-11-05T02:06:11.809615Z"
    }
   },
   "source": [
    "graph_signal_matrix_filename = './62/62_quarter_single_dataset_astcgn.npz'\n",
    "batch_size = 16\n",
    "num_of_hours = 1\n",
    "\n",
    "train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, _mean, _std = load_graphdata_channel1(\n",
    "    graph_signal_matrix_filename, num_of_hours,batch_size)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: /media/nevo/DOCUMENT/OneDrive/100 大体积混凝土温控研究/双屿门大桥/code/ASTGCN-PYG/pytorch_geometric_temporal/notebooks/data/heat\n",
      "load file: ./62/62_quarter_single_dataset_astcgn.npz\n",
      "train: torch.Size([55, 62, 1, 15]) torch.Size([55, 62, 3])\n",
      "val: torch.Size([19, 62, 1, 15]) torch.Size([19, 62, 3])\n",
      "test: torch.Size([19, 62, 1, 15]) torch.Size([19, 62, 3])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "00976f32-67b4-455e-8679-b94b1ebaba82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:06:13.197057Z",
     "start_time": "2024-11-05T02:06:13.189698Z"
    }
   },
   "source": [
    "def get_adjacency_matrix(distance_df_filename, num_of_vertices, id_filename=None):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    distance_df_filename: str, path of the csv file contains edges information\n",
    "    num_of_vertices: int, the number of vertices\n",
    "    Returns\n",
    "    ----------\n",
    "    A: np.ndarray, adjacency matrix\n",
    "    '''\n",
    "    if 'npy' in distance_df_filename:  # false\n",
    "        adj_mx = np.load(distance_df_filename)\n",
    "        return adj_mx, None\n",
    "    else:\n",
    "\n",
    "        #--------------------------------------------- read from here\n",
    "        import csv\n",
    "        A = np.zeros((int(num_of_vertices), int(num_of_vertices)),dtype=np.float32)\n",
    "        distaneA = np.zeros((int(num_of_vertices), int(num_of_vertices)), dtype=np.float32)\n",
    "\n",
    "        #------------ Ignore\n",
    "        if id_filename: # false\n",
    "            with open(id_filename, 'r') as f:\n",
    "                id_dict = {int(i): idx for idx, i in enumerate(f.read().strip().split('\\n'))}  # 把节点id（idx）映射成从0开始的索引\n",
    "\n",
    "            with open(distance_df_filename, 'r') as f:\n",
    "                f.readline()\n",
    "                reader = csv.reader(f)\n",
    "                for row in reader:\n",
    "                    if len(row) != 3:\n",
    "                        continue\n",
    "                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n",
    "                    A[id_dict[i], id_dict[j]] = 1\n",
    "                    distaneA[id_dict[i], id_dict[j]] = distance\n",
    "            return A, distaneA\n",
    "\n",
    "        else:\n",
    "         #-------------Continue reading\n",
    "            with open(distance_df_filename, 'r') as f:\n",
    "                f.readline()\n",
    "                reader = csv.reader(f)\n",
    "                for row in reader:\n",
    "                    if len(row) != 3:\n",
    "                        continue\n",
    "                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n",
    "                    A[i, j] = 1\n",
    "                    distaneA[i, j] = distance\n",
    "            return A, distaneA"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "854a2a4b-e6d8-443b-b4f1-9b2a0ffa3d6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:06:14.620193Z",
     "start_time": "2024-11-05T02:06:14.610948Z"
    }
   },
   "source": [
    "id_filename = './62/62_id_filename.csv'\n",
    "# 邻接矩阵文件的路径，即存储交通网络连接信息的文件。\n",
    "adj_filename = './62/62_node_distance.csv'\n",
    "# num_of_vertices：节点的数量，即传感器的数量\n",
    "num_of_vertices = 62    #62为混凝土内温度节点数量  总数量为66含进出水温节点\n",
    "# get_adjacency_matrix：用于读取邻接矩阵文件并生成邻接矩阵adj_mx和距离矩阵distance_mx。邻接矩阵adj_mx是一个66x66的矩阵，表示节点之间的连接关系。\n",
    "adj_mx, distance_mx = get_adjacency_matrix(adj_filename, num_of_vertices, id_filename)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用 networkx 库创建图并绘制出来。",
   "id": "c4897f9a8e852758"
  },
  {
   "cell_type": "code",
   "id": "ba3aea8f-ccab-4957-a5fe-0b21cf0f9dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:06:15.855572Z",
     "start_time": "2024-11-05T02:06:15.852408Z"
    }
   },
   "source": [
    "# 使用 networkx 库创建图并绘制出来。\n",
    "# 找到邻接矩阵中值为1的位置，这些位置表示节点之间的连接。\n",
    "# rows, cols = np.where(adj_mx == 1)\n",
    "# # 将行和列索引组合成边的列表。\n",
    "# edges = zip(rows.tolist(), cols.tolist())\n",
    "# gr = nx.Graph()\n",
    "# gr.add_edges_from(edges)\n",
    "# nx.draw(gr, node_size=3)\n",
    "# plt.show()"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:06:17.060913Z",
     "start_time": "2024-11-05T02:06:17.058001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建PyTorch张量表示边的索引\n",
    "rows, cols = np.where(adj_mx == 1)\n",
    "edges = zip(rows.tolist(), cols.tolist()) # 将行和列索引组合成边的列表。\n",
    "# torch.LongTensor(np.array([rows, cols]))：将边的行和列索引转换为PyTorch的长整型张量。\n",
    "edge_index_data = torch.LongTensor(np.array([rows, cols])).to(DEVICE)"
   ],
   "id": "4bd123b1f809834c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:06:20.839266Z",
     "start_time": "2024-11-05T02:06:20.807745Z"
    }
   },
   "cell_type": "code",
   "source": "from torch_geometric_temporal.nn.attention import ASTGCN",
   "id": "a83e2eec367a5fef",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:09.757490Z",
     "start_time": "2024-11-05T07:41:09.746876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nb_block = 2\n",
    "in_channels = 1\n",
    "K = 3\n",
    "nb_chev_filter = 16\n",
    "nb_time_filter = 16\n",
    "# time_strides = num_of_hours\n",
    "time_strides = 1\n",
    "num_for_predict = 5\n",
    "len_input = 15\n",
    "#L_tilde = scaled_Laplacian(adj_mx)\n",
    "#cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(DEVICE) for i in cheb_polynomial(L_tilde, K)]\n",
    "net = ASTGCN( nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, num_for_predict, len_input, num_of_vertices).to(DEVICE)\n",
    "\n",
    "print(net)"
   ],
   "id": "c93041300b64c09e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASTGCN(\n",
      "  (_blocklist): ModuleList(\n",
      "    (0): ASTGCNBlock(\n",
      "      (_temporal_attention): TemporalAttention()\n",
      "      (_spatial_attention): SpatialAttention()\n",
      "      (_chebconv_attention): ChebConvAttention(1, 16, K=3, normalization=None)\n",
      "      (_time_convolution): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (_residual_convolution): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (_layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): ASTGCNBlock(\n",
      "      (_temporal_attention): TemporalAttention()\n",
      "      (_spatial_attention): SpatialAttention()\n",
      "      (_chebconv_attention): ChebConvAttention(16, 16, K=3, normalization=None)\n",
      "      (_time_convolution): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (_residual_convolution): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (_layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (_final_conv): Conv2d(15, 5, kernel_size=(1, 16), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:10.600208Z",
     "start_time": "2024-11-05T07:41:10.594608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 打印模型的所有参数及其名称\n",
    "for name, param in net.named_parameters():\n",
    "    print(f\"Layer: {name} | Shape: {param.shape} | Requires Grad: {param.requires_grad}\")"
   ],
   "id": "556a6ee2cd137967",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: _blocklist.0._temporal_attention._U1 | Shape: torch.Size([62]) | Requires Grad: True\n",
      "Layer: _blocklist.0._temporal_attention._U2 | Shape: torch.Size([1, 62]) | Requires Grad: True\n",
      "Layer: _blocklist.0._temporal_attention._U3 | Shape: torch.Size([1]) | Requires Grad: True\n",
      "Layer: _blocklist.0._temporal_attention._be | Shape: torch.Size([1, 15, 15]) | Requires Grad: True\n",
      "Layer: _blocklist.0._temporal_attention._Ve | Shape: torch.Size([15, 15]) | Requires Grad: True\n",
      "Layer: _blocklist.0._spatial_attention._W1 | Shape: torch.Size([15]) | Requires Grad: True\n",
      "Layer: _blocklist.0._spatial_attention._W2 | Shape: torch.Size([1, 15]) | Requires Grad: True\n",
      "Layer: _blocklist.0._spatial_attention._W3 | Shape: torch.Size([1]) | Requires Grad: True\n",
      "Layer: _blocklist.0._spatial_attention._bs | Shape: torch.Size([1, 62, 62]) | Requires Grad: True\n",
      "Layer: _blocklist.0._spatial_attention._Vs | Shape: torch.Size([62, 62]) | Requires Grad: True\n",
      "Layer: _blocklist.0._chebconv_attention._weight | Shape: torch.Size([3, 1, 16]) | Requires Grad: True\n",
      "Layer: _blocklist.0._chebconv_attention._bias | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.0._time_convolution.weight | Shape: torch.Size([16, 16, 1, 3]) | Requires Grad: True\n",
      "Layer: _blocklist.0._time_convolution.bias | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.0._residual_convolution.weight | Shape: torch.Size([16, 1, 1, 1]) | Requires Grad: True\n",
      "Layer: _blocklist.0._residual_convolution.bias | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.0._layer_norm.weight | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.0._layer_norm.bias | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.1._temporal_attention._U1 | Shape: torch.Size([62]) | Requires Grad: True\n",
      "Layer: _blocklist.1._temporal_attention._U2 | Shape: torch.Size([16, 62]) | Requires Grad: True\n",
      "Layer: _blocklist.1._temporal_attention._U3 | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.1._temporal_attention._be | Shape: torch.Size([1, 15, 15]) | Requires Grad: True\n",
      "Layer: _blocklist.1._temporal_attention._Ve | Shape: torch.Size([15, 15]) | Requires Grad: True\n",
      "Layer: _blocklist.1._spatial_attention._W1 | Shape: torch.Size([15]) | Requires Grad: True\n",
      "Layer: _blocklist.1._spatial_attention._W2 | Shape: torch.Size([16, 15]) | Requires Grad: True\n",
      "Layer: _blocklist.1._spatial_attention._W3 | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.1._spatial_attention._bs | Shape: torch.Size([1, 62, 62]) | Requires Grad: True\n",
      "Layer: _blocklist.1._spatial_attention._Vs | Shape: torch.Size([62, 62]) | Requires Grad: True\n",
      "Layer: _blocklist.1._chebconv_attention._weight | Shape: torch.Size([3, 16, 16]) | Requires Grad: True\n",
      "Layer: _blocklist.1._chebconv_attention._bias | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.1._time_convolution.weight | Shape: torch.Size([16, 16, 1, 3]) | Requires Grad: True\n",
      "Layer: _blocklist.1._time_convolution.bias | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.1._residual_convolution.weight | Shape: torch.Size([16, 16, 1, 1]) | Requires Grad: True\n",
      "Layer: _blocklist.1._residual_convolution.bias | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.1._layer_norm.weight | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _blocklist.1._layer_norm.bias | Shape: torch.Size([16]) | Requires Grad: True\n",
      "Layer: _final_conv.weight | Shape: torch.Size([5, 15, 1, 16]) | Requires Grad: True\n",
      "Layer: _final_conv.bias | Shape: torch.Size([5]) | Requires Grad: True\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:11.726756Z",
     "start_time": "2024-11-05T07:41:11.696451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print('Net\\'s state_dict:')\n",
    "total_param = 0\n",
    "'''\n",
    "state_dict() 方法返回一个字典，其中包含模型的所有参数和缓冲区\n",
    "param_tensor 是参数的名称。\n",
    "param_size 是参数张量的大小。\n",
    "param_device 是参数张量所在的设备。\n",
    "np.prod(param_size) 计算参数张量中所有元素的乘积，即参数的总数。\n",
    "'''\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, '\\t', net.state_dict()[param_tensor].size(), '\\t', net.state_dict()[param_tensor].device)\n",
    "    total_param += np.prod(net.state_dict()[param_tensor].size())\n",
    "print('Net\\'s total params:', total_param)\n",
    "#--------------------------------------------------\n",
    "print('Optimizer\\'s state_dict:')\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, '\\t', optimizer.state_dict()[var_name])"
   ],
   "id": "ff6e8dc7f85deee1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net's state_dict:\n",
      "_blocklist.0._temporal_attention._U1 \t torch.Size([62]) \t cuda:0\n",
      "_blocklist.0._temporal_attention._U2 \t torch.Size([1, 62]) \t cuda:0\n",
      "_blocklist.0._temporal_attention._U3 \t torch.Size([1]) \t cuda:0\n",
      "_blocklist.0._temporal_attention._be \t torch.Size([1, 15, 15]) \t cuda:0\n",
      "_blocklist.0._temporal_attention._Ve \t torch.Size([15, 15]) \t cuda:0\n",
      "_blocklist.0._spatial_attention._W1 \t torch.Size([15]) \t cuda:0\n",
      "_blocklist.0._spatial_attention._W2 \t torch.Size([1, 15]) \t cuda:0\n",
      "_blocklist.0._spatial_attention._W3 \t torch.Size([1]) \t cuda:0\n",
      "_blocklist.0._spatial_attention._bs \t torch.Size([1, 62, 62]) \t cuda:0\n",
      "_blocklist.0._spatial_attention._Vs \t torch.Size([62, 62]) \t cuda:0\n",
      "_blocklist.0._chebconv_attention._weight \t torch.Size([3, 1, 16]) \t cuda:0\n",
      "_blocklist.0._chebconv_attention._bias \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.0._time_convolution.weight \t torch.Size([16, 16, 1, 3]) \t cuda:0\n",
      "_blocklist.0._time_convolution.bias \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.0._residual_convolution.weight \t torch.Size([16, 1, 1, 1]) \t cuda:0\n",
      "_blocklist.0._residual_convolution.bias \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.0._layer_norm.weight \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.0._layer_norm.bias \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.1._temporal_attention._U1 \t torch.Size([62]) \t cuda:0\n",
      "_blocklist.1._temporal_attention._U2 \t torch.Size([16, 62]) \t cuda:0\n",
      "_blocklist.1._temporal_attention._U3 \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.1._temporal_attention._be \t torch.Size([1, 15, 15]) \t cuda:0\n",
      "_blocklist.1._temporal_attention._Ve \t torch.Size([15, 15]) \t cuda:0\n",
      "_blocklist.1._spatial_attention._W1 \t torch.Size([15]) \t cuda:0\n",
      "_blocklist.1._spatial_attention._W2 \t torch.Size([16, 15]) \t cuda:0\n",
      "_blocklist.1._spatial_attention._W3 \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.1._spatial_attention._bs \t torch.Size([1, 62, 62]) \t cuda:0\n",
      "_blocklist.1._spatial_attention._Vs \t torch.Size([62, 62]) \t cuda:0\n",
      "_blocklist.1._chebconv_attention._weight \t torch.Size([3, 16, 16]) \t cuda:0\n",
      "_blocklist.1._chebconv_attention._bias \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.1._time_convolution.weight \t torch.Size([16, 16, 1, 3]) \t cuda:0\n",
      "_blocklist.1._time_convolution.bias \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.1._residual_convolution.weight \t torch.Size([16, 16, 1, 1]) \t cuda:0\n",
      "_blocklist.1._residual_convolution.bias \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.1._layer_norm.weight \t torch.Size([16]) \t cuda:0\n",
      "_blocklist.1._layer_norm.bias \t torch.Size([16]) \t cuda:0\n",
      "_final_conv.weight \t torch.Size([5, 15, 1, 16]) \t cuda:0\n",
      "_final_conv.bias \t torch.Size([5]) \t cuda:0\n",
      "Net's total params: 21762\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]}]\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:12.539060Z",
     "start_time": "2024-11-05T07:41:12.534562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def masked_mae(preds, labels, null_val=np.nan):\n",
    "    '''\n",
    "    :param: preds（预测值）\n",
    "            labels（真实标签）\n",
    "            null_val（表示无效值的标记，默认是 NaN）\n",
    "    '''\n",
    "    if np.isnan(null_val):\n",
    "        # 生成一个掩码 mask，掩码中的每个元素表示 labels 中对应位置是否不是 NaN（即 True 表示不是 NaN，False 表示是 NaN）\n",
    "        # ~ 按位取反运算符\n",
    "        mask = ~torch.isnan(labels)\n",
    "    else:\n",
    "        # 生成一个掩码 mask，掩码中的每个元素表示 labels 中对应位置是否不等于 null_val\n",
    "        mask = (labels != null_val)\n",
    "    mask = mask.float()\n",
    "    mask /= torch.mean((mask))\n",
    "\n",
    "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
    "    # 计算绝对误差: 计算预测值 preds 和真实标签 labels 之间的绝对误差\n",
    "    loss = torch.abs(preds - labels)\n",
    "    # 应用掩码: 将绝对误差与掩码相乘，这样掩码为 0 的位置（即无效值位置）的误差将被忽略（置为 0）\n",
    "    loss = loss * mask\n",
    "    # 处理误差中的 NaN 值: 将误差中的 NaN 值替换为 0。这是为了防止后续计算中出现 NaN 值\n",
    "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
    "    # 返回带掩码的 MAE: 计算并返回误差的均值，即带掩码的平均绝对误差\n",
    "    return torch.mean(loss)"
   ],
   "id": "e88604fa28faf102",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:13.237492Z",
     "start_time": "2024-11-05T07:41:13.226110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "masked_flag=0\n",
    "criterion = nn.L1Loss().to(DEVICE)\n",
    "criterion_masked = masked_mae\n",
    "loss_function = 'mse'\n",
    "\n",
    "metric_method = 'unmask'\n",
    "missing_value=0.0"
   ],
   "id": "dd607762fdc063c2",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:13.892720Z",
     "start_time": "2024-11-05T07:41:13.886003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if loss_function=='masked_mse':\n",
    "    criterion_masked = masked_mse         #nn.MSELoss().to(DEVICE)\n",
    "    masked_flag=1\n",
    "elif loss_function=='masked_mae':\n",
    "    criterion_masked = masked_mae\n",
    "    masked_flag = 1\n",
    "elif loss_function == 'mae':\n",
    "    criterion = nn.L1Loss().to(DEVICE)\n",
    "    masked_flag = 0\n",
    "elif loss_function == 'rmse':\n",
    "    criterion = nn.MSELoss().to(DEVICE)\n",
    "    masked_flag= 0"
   ],
   "id": "6f187528d49ead9d",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:14.606890Z",
     "start_time": "2024-11-05T07:41:14.584231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_val_loss_mstgcn(net, val_loader, criterion,  masked_flag,missing_value,sw, epoch, edge_index_data, limit=None):\n",
    "    '''\n",
    "    for rnn, compute mean loss on validation set\n",
    "    :param net: model\n",
    "    :param val_loader: torch.utils.data.utils.DataLoader\n",
    "    :param criterion: torch.nn.MSELoss\n",
    "    :param sw: tensorboardX.SummaryWriter\n",
    "    :param global_step: int, current global_step\n",
    "    :param limit: int,\n",
    "    :return: val_loss\n",
    "    '''\n",
    "    # 将模型设置为评估模式 net.eval()\n",
    "    net.train(False)  # ensure dropout layers are in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loader_length = len(val_loader)  # nb of batch\n",
    "        tmp = []  # batch loss\n",
    "        for batch_index, batch_data in enumerate(val_loader):\n",
    "            encoder_inputs, labels = batch_data\n",
    "            outputs = net(encoder_inputs, edge_index_data)\n",
    "            # 根据 masked_flag 来选择合适的损失函数。如果 masked_flag 为真，则使用带掩码的损失函数，否则使用标准损失函数。\n",
    "            if masked_flag:\n",
    "                loss = criterion(outputs, labels, missing_value)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            tmp.append(loss.item())\n",
    "            if batch_index % 100 == 0:\n",
    "                print('validation batch %s / %s, loss: %.2f' % (batch_index + 1, val_loader_length, loss.item()))\n",
    "            if (limit is not None) and batch_index >= limit:\n",
    "                break\n",
    "\n",
    "        validation_loss = sum(tmp) / len(tmp)\n",
    "        sw.add_scalar('validation_loss', validation_loss, epoch)\n",
    "    return validation_loss"
   ],
   "id": "86bbdfc1071212fd",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:15.339020Z",
     "start_time": "2024-11-05T07:41:15.327206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "global_step = 0\n",
    "best_epoch = 0\n",
    "# np.inf 表示正无穷大\n",
    "best_val_loss = np.inf\n",
    "start_time= time()"
   ],
   "id": "3f50c729f876bec5",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T07:41:15.970401Z",
     "start_time": "2024-11-05T07:41:15.963742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train model\n",
    "def train_model():\n",
    "    for epoch in range(20):\n",
    "        params_filename = os.path.join('./data/pems-dataset/', 'epoch_%s.params' % epoch)\n",
    "        masked_flag = 1\n",
    "        if masked_flag:\n",
    "            val_loss = compute_val_loss_mstgcn(net, val_loader, criterion_masked, masked_flag,missing_value,sw, epoch,edge_index_data)\n",
    "        else:\n",
    "            val_loss = compute_val_loss_mstgcn(net, val_loader, criterion, masked_flag, missing_value, sw, epoch,edge_index_data)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(net.state_dict(), params_filename)\n",
    "            print('save parameters to file: %s' % params_filename)\n",
    "\n",
    "        # 训练模式\n",
    "        net.train()  # ensure dropout layers are in train mode\n",
    "\n",
    "        for batch_index, batch_data in enumerate(train_loader):\n",
    "            encoder_inputs, labels = batch_data   # encoder_inputs torch.Size([32, 307, 1, 12])  label torch.Size([32, 307, 12])\n",
    "            # 清除上一步的梯度。\n",
    "            optimizer.zero_grad()\n",
    "            # 前向传播计算模型输出\n",
    "            outputs = net(encoder_inputs, edge_index_data) # torch.Size([32, 307, 12])\n",
    "\n",
    "            if masked_flag:\n",
    "                loss = criterion_masked(outputs, labels,missing_value)\n",
    "            else :\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向传播计算梯度\n",
    "            loss.backward()\n",
    "            #  更新模型参数\n",
    "            optimizer.step()\n",
    "            training_loss = loss.item()\n",
    "            global_step += 1\n",
    "            sw.add_scalar('training_loss', training_loss, global_step)\n",
    "\n",
    "            if global_step % 200 == 0:\n",
    "                print('global step: %s, training loss: %.2f, time: %.2fs' % (global_step, training_loss, time() - start_time))"
   ],
   "id": "65dba54e02357c50",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T08:43:05.660956Z",
     "start_time": "2024-11-05T07:42:56.634987Z"
    }
   },
   "cell_type": "code",
   "source": "train_model()",
   "id": "4619587398d80e61",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[84], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[82], line 7\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m masked_flag \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m masked_flag:\n\u001B[0;32m----> 7\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_val_loss_mstgcn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_masked\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmasked_flag\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmissing_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43msw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43medge_index_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m compute_val_loss_mstgcn(net, val_loader, criterion, masked_flag, missing_value, sw, epoch,edge_index_data)\n",
      "Cell \u001B[0;32mIn[80], line 22\u001B[0m, in \u001B[0;36mcompute_val_loss_mstgcn\u001B[0;34m(net, val_loader, criterion, masked_flag, missing_value, sw, epoch, edge_index_data, limit)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# 根据 masked_flag 来选择合适的损失函数。如果 masked_flag 为真，则使用带掩码的损失函数，否则使用标准损失函数。\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m masked_flag:\n\u001B[0;32m---> 22\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     24\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n",
      "Cell \u001B[0;32mIn[77], line 19\u001B[0m, in \u001B[0;36mmasked_mae\u001B[0;34m(preds, labels, null_val)\u001B[0m\n\u001B[1;32m     17\u001B[0m mask \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(torch\u001B[38;5;241m.\u001B[39misnan(mask), torch\u001B[38;5;241m.\u001B[39mzeros_like(mask), mask)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# 计算绝对误差: 计算预测值 preds 和真实标签 labels 之间的绝对误差\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mabs(\u001B[43mpreds\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# 应用掩码: 将绝对误差与掩码相乘，这样掩码为 0 的位置（即无效值位置）的误差将被忽略（置为 0）\u001B[39;00m\n\u001B[1;32m     21\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m*\u001B[39m mask\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# model.eval()\n",
    "net.train(False)  # ensure dropout layers are in evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_loader_length = len(test_loader)  # nb of batch\n",
    "    tmp = []  # batch loss\n",
    "    for batch_index, batch_data in enumerate(test_loader):\n",
    "        encoder_inputs, labels = batch_data\n",
    "        outputs = net(encoder_inputs, edge_index_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        tmp.append(loss.item())\n",
    "        if batch_index % 100 == 0:\n",
    "            print('test_loss batch %s / %s, loss: %.2f' % (batch_index + 1, test_loader_length, loss.item()))\n",
    "\n",
    "\n",
    "    test_loss = sum(tmp) / len(tmp)\n",
    "    sw.add_scalar('test_loss', test_loss, epoch)\n",
    "print(test_loss)"
   ],
   "id": "b1912e37c5103150"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pickig a random time point and visualizing the predictions of the first 50 detectors",
   "id": "a8131a468e81f7f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_output = outputs[0]  # prediction\n",
    "sample_labels = labels[0] # truth\n",
    "print(sample_output.shape, sample_labels.shape)\n",
    "sample_labels[0][1]"
   ],
   "id": "7dff9c5f00cd83fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(30,4), dpi=80)\n",
    "for i in range(50):\n",
    "    new_i = i * 12\n",
    "    plt.plot(range(0+new_i,12+new_i),sample_output[i].detach().cpu().numpy(), color = 'red')\n",
    "    plt.plot(range(0+new_i,12+new_i),sample_labels[i].cpu().numpy(), color='blue')\n",
    "plt.show()"
   ],
   "id": "ef3906e90f37da88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
